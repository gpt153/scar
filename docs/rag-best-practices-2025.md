# RAG Best Practices & Implementation Patterns (2025-2026)

**Research Date**: January 10, 2026
**Archon Project ID**: 92560dbd-9811-475a-8b7c-460d53a23fe7
**Sources**: Industry research, academic papers, and expert implementations (Cole Medin, Docker, Neo4j, Microsoft)

---

## Executive Summary

As of 2025, **RAG powers an estimated 60% of production AI applications** and has become the cornerstone of enterprise AI adoption. The field is evolving from simple retrieval-augmented generation toward **Context Engineering**, which emerged as the dominant technical approach in late 2025.

**Key Trend**: The shift from "RAG" to "Context" - focusing on engineering the right context for AI systems rather than just augmenting generation with retrieval.

---

## üéØ 2025 RAG Landscape

### Evolution of RAG Architecture

**Traditional RAG** (2023-2024):
- Simple vector search + LLM generation
- Single retrieval strategy
- Basic chunking (fixed size)

**Modern RAG** (2025-2026):
- **Context Engineering** - Strategic context assembly
- **Agentic RAG** - AI agents decide when/what to retrieve
- **Hybrid Retrieval** - Multiple strategies combined
- **Graph-Enhanced RAG** - Relationship-aware context
- **Adaptive Retrieval** - Dynamic strategy selection based on query intent

### Industry Adoption

- **60% of production AI apps** use RAG (2025 estimate)
- **Enterprise AI**: RAG is the dominant pattern for knowledge-intensive applications
- **Compliance**: RAG enables auditable, source-attributed responses
- **Cost Efficiency**: More effective than continuous model fine-tuning

---

## üìä Latest Academic Research (January 2025)

### ArXiv Paper: "Enhancing Retrieval-Augmented Generation" (2501.07391)

**Systematically Investigated Factors**:
1. Language model size variations
2. Prompt design approaches
3. Document chunk size optimization
4. Knowledge base sizing
5. Retrieval stride configuration
6. Query expansion techniques
7. Contrastive In-Context Learning
8. Multilingual knowledge bases
9. **Focus Mode** - Sentence-level context retrieval

**Key Finding**: "Balance between contextual richness and retrieval-generation efficiency"

**Main Recommendation**: Tailor RAG systems by understanding component interactions across diverse applications.

**Source**: [ArXiv 2501.07391](https://arxiv.org/abs/2501.07391)

---

## üèóÔ∏è Cole Medin's RAG Architecture

### Background

Cole Medin is a leading Generative AI specialist and AI educator focusing on practical RAG implementations, agentic systems, and AI coding assistants. His work emphasizes **production-ready, open-source solutions** that developers can immediately deploy.

### Key Projects

#### 1. **Crawl4AI RAG MCP Server** ‚≠ê 2k stars

**Repository**: [github.com/coleam00/mcp-crawl4ai-rag](https://github.com/coleam00/mcp-crawl4ai-rag)

**Architecture Overview**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Model Context Protocol (MCP)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ               ‚îÇ                   ‚îÇ
    ‚ñº               ‚ñº                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇCrawl4AI ‚îÇ  ‚îÇ  Supabase   ‚îÇ  ‚îÇ Neo4j (Optional) ‚îÇ
‚îÇ Engine  ‚îÇ  ‚îÇ  +pgvector  ‚îÇ  ‚îÇ Knowledge Graph  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Three-Layer Architecture**:

1. **Data Collection Layer**
   - Intelligent URL detection
   - Recursive crawling with parallelization
   - Automatic sitemap/robots.txt handling
   - Content extraction and cleaning

2. **Storage & Indexing Layer**
   - Supabase (PostgreSQL + pgvector)
   - Header-aware intelligent chunking
   - OpenAI embeddings for semantic search
   - Metadata preservation

3. **Retrieval Layer**
   - Hybrid search (vector + keyword)
   - Optional cross-encoder reranking
   - Code example extraction
   - Knowledge graph integration

**Five RAG Strategies**:

1. **Contextual Embeddings**: Enriches chunks with document-level context via LLM
2. **Hybrid Search**: Merges semantic (vector) and keyword-based (BM25) results
3. **Agentic RAG**: Separates code extraction and summarization
4. **Reranking**: Cross-encoder scoring for precision
5. **Knowledge Graph**: Neo4j-based hallucination detection through repo structure mapping

**Key Insight**: Cole's approach emphasizes **flexible, modular RAG** where strategies can be mixed and matched based on use case.

#### 2. **Context Engineering Intro** ‚≠ê 12.1k stars

**Repository**: [github.com/coleam00/context-engineering-intro](https://github.com/coleam00/context-engineering-intro)

**Core Philosophy**: "Context is more important than the model itself"

**Techniques**:
- Strategic context assembly
- Relevance-based filtering
- Dynamic context expansion
- Cross-reference linking

**Focus**: Enhancing AI coding assistant performance through better context engineering

#### 3. **oTTomator Agents** ‚≠ê 5.2k stars

**Repository**: [github.com/coleam00/ottomator-agents](https://github.com/coleam00/ottomator-agents)

**Contains**: Production-ready n8n workflow templates for agentic RAG systems

**Notable Template**: "Ultimate_Agentic_RAG_AI_Agent_Template.json"
- Complete end-to-end RAG agent
- Supabase vector DB integration
- Multi-client document processing
- Production-tested workflows

### Cole's RAG Principles (Based on His Work)

1. **Start Simple, Add Complexity**: Begin with basic RAG, layer in advanced features as needed
2. **Make It Agentic**: Let AI decide when/what to retrieve rather than always retrieving
3. **Open Source Everything**: All templates and tools publicly available
4. **Production-First**: Focus on deployable, maintainable solutions
5. **Context Over Model**: Better context beats better models

---

## üîß Advanced RAG Techniques for 2025

### 1. Chunking Strategies

**Benchmark Results** (2025):
- **400-token chunks** achieved 88-89% recall
- **10-20% overlap** is the sweet spot
- **Recursive chunking** is the default choice for 80% of RAG applications

**Recommended Approach**:

```python
# Starting Configuration
chunk_size = 512-1024 tokens
overlap = 10-20%
strategy = "recursive"  # Default for most cases

# For Code
chunk_size = 2000 tokens
code_aware = True  # Use AST-based splitting
respect_functions = True  # Don't split mid-function

# For Documentation
chunk_size = 1000 tokens
overlap = 100 chars
respect_word_boundaries = True
```

**Chunking Strategies Ranked**:

1. **Recursive Chunking** (80% use case)
   - Balances simplicity with structure awareness
   - Splits by hierarchical delimiters
   - Best for most applications

2. **Semantic Chunking**
   - Chunks by meaning/topic shifts
   - Uses embedding similarity
   - Better for narrative content

3. **Code-Aware Chunking**
   - AST-based splitting
   - Preserves function/class boundaries
   - Essential for code repositories

4. **Fixed-Size Chunking**
   - Simple, predictable
   - Use only for uniform content
   - Legacy approach

**Source**: [Firecrawl - Best Chunking Strategies RAG 2025](https://www.firecrawl.dev/blog/best-chunking-strategies-rag-2025)

### 2. Embedding Models (2025 Recommendations)

**Top Choices**:

1. **OpenAI text-embedding-3-small** (Default)
   - 1536 dimensions
   - Best cost/performance ratio
   - Industry standard

2. **Cohere embed-v3**
   - Multilingual support
   - Compression support
   - Good for international apps

3. **SBERT/MiniLM** (Local deployment)
   - No API costs
   - Faster inference
   - Good for privacy-sensitive apps

4. **E5/Instruct**
   - Instruction-tuned
   - Better for specific domains

**Best Practice**: **Always normalize embeddings** before storage and comparison.

### 3. Hybrid Search Architecture

**Why Hybrid?**
- **Vector search** catches semantic similarity
- **BM25 keyword search** catches exact terms
- **Combined via RRF** (Reciprocal Rank Fusion) = best of both worlds

**Implementation**:

```yaml
strategies:
  - type: chunked-embeddings
    embedding_model: openai/text-embedding-3-small
    limit: 20

  - type: bm25
    k1: 1.5
    b: 0.75
    limit: 15

fusion:
  strategy: rrf  # Reciprocal Rank Fusion
  k: 60
  deduplicate: true
  final_limit: 5
```

**Results**: Hybrid retrieval is **low-risk, high-return** - recommended for all production systems.

**Source**: [Docker cagent RAG Documentation](https://docs.docker.com/ai/cagent/rag/)

### 4. Reranking

**When to Use**:
- When precision matters more than speed
- Top-k results need quality boost
- Post-retrieval refinement

**Recommended Models**:
- **Cross-encoders** (highest accuracy)
- **Cohere rerank-v3**
- **BGE reranker**

**Configuration**:

```yaml
reranking:
  model: openai/gpt-5-mini
  threshold: 0.3
  criteria: |
    Prioritize:
    - Official documentation over community content
    - Recent information over outdated material
    - Practical examples over theory
    - Code implementations over design discussions
  limit: 5
```

**Trade-off**: Adds latency and API costs, but significantly improves relevance.

### 5. Query Expansion & HyDE

**Query Expansion**:
- Reformulate user queries to capture synonyms
- Expand acronyms and technical terms
- Generate alternative phrasings

**HyDE (Hypothetical Document Embeddings)**:
- Generate hypothetical answer to query
- Embed the hypothetical answer
- Search for similar documents
- Returns documents that would answer the query

**Example**:

```python
# Original Query
"How do I retry failed requests?"

# HyDE Generated
"To retry failed requests, you can use exponential backoff
with a maximum of 3 attempts. Here's an example implementation..."

# Search uses HyDE embedding to find actual documentation
```

**Benefit**: Bridges the gap between how users ask and how docs are written.

---

## üöÄ Advanced RAG Patterns

### 1. Agentic RAG

**Concept**: AI agent decides **when** to retrieve, **what** to retrieve, and **how much** to retrieve.

**vs Traditional RAG**:
- Traditional: Always retrieves on every query
- Agentic: Retrieves only when needed

**Implementation** (Cole Medin's Approach):

```python
# Agent decides based on query analysis
if agent.needs_external_knowledge(query):
    context = rag_system.retrieve(
        query=query,
        strategy=agent.select_strategy(query),
        num_results=agent.determine_needed_context(query)
    )
else:
    # Use agent's built-in knowledge
    context = None
```

**Benefits**:
- Reduced API costs
- Faster responses when retrieval not needed
- More intelligent context selection

### 2. Graph-RAG (Neo4j)

**When to Use**:
- Highly connected data (code repositories, documentation hierarchies)
- Relationship-driven queries
- Hallucination detection needed

**Architecture**:

```
Documents ‚Üí [Extract Entities] ‚Üí Neo4j Graph
                                      ‚Üì
Query ‚Üí [Vector Search] ‚Üí Documents ‚Üê [Graph Traversal]
                                      ‚Üì
                              [Verify Relationships]
                                      ‚Üì
                              Final Context ‚Üí LLM
```

**Key Advantage**: Can verify if generated information aligns with actual relationships in knowledge graph.

**Source**: [Neo4j - Advanced RAG Techniques](https://neo4j.com/blog/genai/advanced-rag-techniques/)

### 3. Long RAG

**Purpose**: Handle lengthy documents more effectively

**Approach**:
- Process longer retrieval units (sections, entire documents)
- Hierarchical chunking (summaries + details)
- Progressive disclosure of context

**Use Cases**:
- Legal documents
- Research papers
- Technical specifications

### 4. SELF-RAG

**Key Innovation**: Self-reflective mechanism

**Process**:
1. Generate initial response
2. Self-critique: "Is this factually accurate?"
3. If uncertain ‚Üí retrieve more context
4. Regenerate with additional context
5. Verify against sources

**Benefit**: Significantly reduces hallucinations

---

## üìà RAG Evaluation (2025 Best Practices)

### Core Metrics

**Retrieval Quality**:
1. **Context Precision**: % of retrieved chunks that are relevant
2. **Context Recall**: % of relevant chunks that were retrieved
3. **Retrieval Latency**: Time to retrieve context

**Generation Quality**:
1. **Faithfulness**: Generated response aligns with retrieved context
2. **Answer Relevance**: Response actually answers the question
3. **Hallucination Rate**: % of responses with unsupported claims

### Recommended Tools (2025)

1. **Braintrust** - RAG evaluation platform
2. **EvidentlyAI** - Open-source RAG metrics
3. **Orq.ai** - RAG evaluation suite
4. **LangSmith** - LangChain evaluation tools

**Best Practice**: "Iterative fine-tuning of both retrieval and generative components, creating a feedback loop"

**Source**: [Braintrust - Best RAG Evaluation Tools 2025](https://www.braintrust.dev/articles/best-rag-evaluation-tools)

---

## üé® Implementation Decision Tree

### When to Use RAG?

‚úÖ **USE RAG when**:
- Content is too large for context window (>50K tokens)
- Content changes frequently (docs, knowledge bases)
- Need source attribution for compliance
- Multiple knowledge sources to integrate
- Want to avoid constant model fine-tuning

‚ùå **DON'T USE RAG when**:
- Content fits in system prompt (<10K tokens)
- Information is static (include in prompt)
- Need real-time data (RAG uses snapshots)
- Queries are simple fact lookups (use database)

### Which Retrieval Strategy?

```
Start Here
    ‚îÇ
    ‚îú‚îÄ‚Üí Documentation?
    ‚îÇ   ‚îî‚îÄ‚Üí Semantic Search (Embeddings)
    ‚îÇ
    ‚îú‚îÄ‚Üí Code?
    ‚îÇ   ‚îî‚îÄ‚Üí Hybrid (BM25 + Embeddings)
    ‚îÇ
    ‚îú‚îÄ‚Üí Technical terms/APIs?
    ‚îÇ   ‚îî‚îÄ‚Üí BM25 Keyword Search
    ‚îÇ
    ‚îú‚îÄ‚Üí Complex relationships?
    ‚îÇ   ‚îî‚îÄ‚Üí Graph-RAG (Neo4j)
    ‚îÇ
    ‚îî‚îÄ‚Üí Production system?
        ‚îî‚îÄ‚Üí Hybrid + Reranking
```

### Tuning Guide

**If retrieval misses relevant content**:
- ‚Üë Increase chunk `overlap`
- ‚Üë Increase retrieval `limit`
- ‚Üì Decrease `threshold`
- ‚ûï Add more retrieval strategies

**If too many irrelevant results**:
- ‚Üì Decrease chunk `size`
- ‚Üì Decrease retrieval `limit`
- ‚Üë Increase `threshold`
- ‚ûï Add reranking

**If indexing too slow**:
- ‚Üë Increase `batch_size`
- ‚Üë Increase `max_embedding_concurrency`
- ‚Üí Switch to BM25 (local, no API)
- ‚Üí Use smaller embedding models

**If results lack context**:
- ‚Üë Increase chunk `size`
- ‚Üë Increase chunk `overlap`
- ‚Üí Enable `return_full_content`
- ‚ûï Add neighboring chunks to results

---

## üí° Industry-Specific Recommendations

### Healthcare
- **Architecture**: Long RAG + SELF-RAG
- **Why**: Context preservation + accuracy critical
- **Chunking**: Large chunks (2000+ tokens) with high overlap
- **Verification**: Mandatory source attribution

### E-commerce
- **Architecture**: Hybrid search + real-time APIs
- **Why**: Both product search (exact) and recommendations (semantic)
- **Chunking**: Small chunks (500 tokens) for product attributes
- **Integration**: Combine RAG with inventory APIs

### Legal/Compliance
- **Architecture**: Graph-RAG + SELF-RAG
- **Why**: Relationship tracking + hallucination prevention
- **Chunking**: Document-level with hierarchical summaries
- **Verification**: Citation to source paragraphs required

### Software Development
- **Architecture**: Code-aware chunking + Agentic RAG
- **Why**: Preserve code structure, retrieve only when needed
- **Chunking**: AST-based, function-level
- **Graph**: Repository structure in Neo4j

---

## üîÆ Looking Ahead: 2026 Predictions

### Emerging Trends

1. **Multimodal RAG**
   - Cross-modal retrieval (text, images, video, audio)
   - Unified embedding spaces
   - Example: "Show me documentation with diagrams about X"

2. **Agentic RAG Becomes Standard**
   - AI agents orchestrate retrieval
   - Dynamic strategy selection
   - Self-improving retrieval patterns

3. **Context Engineering Replaces RAG**
   - Broader framework than just retrieval
   - Strategic context assembly from multiple sources
   - Relationship-aware context graphs

4. **Real-Time Knowledge Updates**
   - Streaming updates to knowledge bases
   - Incremental indexing
   - Event-driven re-indexing

5. **Federated RAG**
   - Multi-tenant knowledge isolation
   - Privacy-preserving retrieval
   - Cross-organizational knowledge sharing (with permissions)

---

## üìö Key Takeaways

### For Developers

1. **Start Simple**: Basic vector search + GPT-4 covers 70% of use cases
2. **Measure Everything**: Implement evaluation from day one
3. **Iterate Based on Data**: Let metrics guide optimization
4. **Chunk Size Matters**: 400-1024 tokens with 10-20% overlap
5. **Hybrid is Safe**: Combining strategies rarely hurts, often helps

### For Architects

1. **RAG is Infrastructure**: Treat it like a database, not a feature
2. **Plan for Scale**: Vector search becomes expensive at 100M+ embeddings
3. **Multi-Strategy**: Support multiple retrieval approaches
4. **Graph for Relations**: Use Neo4j when connections matter
5. **Compliance First**: Source attribution and audit trails from start

### For Product Teams

1. **60% of AI Apps Use RAG**: It's the dominant pattern
2. **Cost vs Fine-Tuning**: RAG is cheaper than constant retraining
3. **User Trust**: Source citations dramatically increase trust
4. **Latency Matters**: Retrieval + generation takes time, plan UX accordingly
5. **Content is King**: RAG quality depends on content quality

---

## üîó Sources & Further Reading

### Academic Papers
- [ArXiv 2501.07391 - Enhancing RAG Study](https://arxiv.org/abs/2501.07391)

### Technical Documentation
- [Docker cagent RAG Documentation](https://docs.docker.com/ai/cagent/rag/)
- [Docker GenAI Leveraging RAG](https://docs.docker.com/guides/genai-leveraging-rag/)
- [Microsoft Azure AI Search RAG](https://learn.microsoft.com/en-us/azure/search/retrieval-augmented-generation-overview)

### Best Practices & Guides
- [Firecrawl - Best Chunking Strategies RAG 2025](https://www.firecrawl.dev/blog/best-chunking-strategies-rag-2025)
- [Neo4j - Advanced RAG Techniques](https://neo4j.com/blog/genai/advanced-rag-techniques/)
- [Eden AI - 2025 Guide to RAG](https://www.edenai.co/post/the-2025-guide-to-retrieval-augmented-generation-rag)
- [Chitika - RAG Definitive Guide 2025](https://www.chitika.com/retrieval-augmented-generation-rag-the-definitive-guide-2025/)
- [RAGFlow - From RAG to Context](https://ragflow.io/blog/rag-review-2025-from-rag-to-context)

### Evaluation Tools
- [Braintrust - Best RAG Evaluation Tools 2025](https://www.braintrust.dev/articles/best-rag-evaluation-tools)
- [EvidentlyAI - RAG Evaluation Guide](https://www.evidentlyai.com/llm-guide/rag-evaluation)
- [Orq.ai - RAG Evaluation Best Practices](https://orq.ai/blog/rag-evaluation)
- [Google Cloud - Optimizing RAG Retrieval](https://cloud.google.com/blog/products/ai-machine-learning/optimizing-rag-retrieval)

### Cole Medin Resources
- [GitHub - Crawl4AI RAG MCP Server](https://github.com/coleam00/mcp-crawl4ai-rag)
- [GitHub - Context Engineering Intro](https://github.com/coleam00/context-engineering-intro)
- [GitHub - oTTomator Agents](https://github.com/coleam00/ottomator-agents)
- [GitHub - AI Agents Masterclass](https://github.com/coleam00/ai-agents-masterclass)
- [GitHub - Local AI Packaged](https://github.com/coleam00/local-ai-packaged)
- [Microsoft Learn - Cole Medin](https://learn.microsoft.com/en-us/community/learn-with/cole-medin/)
- [n8n Community - Cole's RAG Agent](https://community.n8n.io/t/this-rag-ai-agent-with-n8n-supabase-is-the-real-deal/54346)
- [PulseMCP - Crawl4AI MCP Server](https://www.pulsemcp.com/servers/coleam00-crawl4ai-rag)

### Implementation Resources
- [Medium - Optimizing Chunking for RAG](https://medium.com/@adnanmasood/optimizing-chunking-embedding-and-vectorization-for-retrieval-augmented-generation-ea3b083b68f7)
- [Medium - 2025 RAG Retrieval Guide](https://medium.com/@mehulpratapsingh/2025s-ultimate-guide-to-rag-retrieval-how-to-pick-the-right-method-and-why-your-ai-s-success-2cedcda99f8a)
- [Weaviate - Chunking Strategies for RAG](https://weaviate.io/blog/chunking-strategies-for-rag)
- [Meilisearch - 9 Advanced RAG Techniques](https://www.meilisearch.com/blog/rag-techniques)
- [Stack Overflow - Chunking in RAG Applications](https://stackoverflow.blog/2024/12/27/breaking-up-is-hard-to-do-chunking-in-rag-applications/)

---

**Document Version**: 1.0
**Last Updated**: January 10, 2026
**Research Status**: ‚úÖ Comprehensive (30+ sources)
**Archon Crawls**: 5 sources being indexed
**Next Update**: When crawls complete + additional sources identified
